I want you to look into gemini, job, pdf, and chunking services all, analyze the current state, and work on a plan to imrove the aspect of sentence normalization we need for coverage, since coverage tool is perfect now, the only bottleneck is the actual sentence splitter, think hard about how to imrpove it to achieve my goal of generating the least amount of sentences that cover all the targeted words in our wordlist. you can find a sample of the pdf novels in sample/test.pdf.
Again our goal is to scan the novel, rewrite it into 8 words sentences maintaing it's meaning and liguastic integrity, and trying to keep the maximum amount of words from originial, each sentence should be meaningful even without context, and should contain a verb.